{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "from pyspark.ml.recommendation import ALS\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.sql.functions import col, exp, lit, expr, array, size, when, array_intersect\n",
    "from pyspark.sql.types import IntegerType\n",
    "from sklearn.model_selection import train_test_split\n",
    "from lightgbm import LGBMRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 14:00:29 WARN Utils: Your hostname, MacBook-Air-Nasdorm.local resolves to a loopback address: 127.0.0.1; using 192.168.31.71 instead (on interface en0)\n",
      "24/11/27 14:00:29 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/11/27 14:00:30 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"MovieLensALS\").getOrCreate()\n",
    "\n",
    "data_path = '../data/ml-100k/u.data'\n",
    "columns = [\"userId\", \"movieId\", \"rating\", \"timestamp\"]\n",
    "ratings = spark.read.csv(data_path, sep=\"\\t\", inferSchema=True).toDF(*columns)\n",
    "\n",
    "ratings = ratings.withColumn(\"userId\", col(\"userId\").cast(IntegerType()))\n",
    "ratings = ratings.withColumn(\"movieId\", col(\"movieId\").cast(IntegerType()))\n",
    "\n",
    "max_timestamp = ratings.agg({'timestamp': 'max'}).collect()[0][0]\n",
    "ratings = ratings.withColumn('weight', exp(-(lit(max_timestamp) - col('timestamp')) / lit(10**6)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|movieId|            title|release_date|video_release_date|            imdb_url|unknown|Action|Adventure|Animation|Children's|Comedy|Crime|Documentary|Drama|Fantasy|Film-Noir|Horror|Musical|Mystery|Romance|Sci-Fi|Thriller|War|Western|\n",
      "+-------+-----------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "|      1| Toy Story (1995)| 01-Jan-1995|              NULL|http://us.imdb.co...|      0|     0|        0|        1|         1|     1|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|      2| GoldenEye (1995)| 01-Jan-1995|              NULL|http://us.imdb.co...|      0|     1|        1|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|      3|Four Rooms (1995)| 01-Jan-1995|              NULL|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    0|          0|    0|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "|      4|Get Shorty (1995)| 01-Jan-1995|              NULL|http://us.imdb.co...|      0|     1|        0|        0|         0|     1|    0|          0|    1|      0|        0|     0|      0|      0|      0|     0|       0|  0|      0|\n",
      "|      5|   Copycat (1995)| 01-Jan-1995|              NULL|http://us.imdb.co...|      0|     0|        0|        0|         0|     0|    1|          0|    1|      0|        0|     0|      0|      0|      0|     0|       1|  0|      0|\n",
      "+-------+-----------------+------------+------------------+--------------------+-------+------+---------+---------+----------+------+-----+-----------+-----+-------+---------+------+-------+-------+-------+------+--------+---+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "movies_path = '../data/ml-100k/u.item'\n",
    "\n",
    "movies_columns = [\n",
    "    \"movieId\", \"title\", \"release_date\", \"video_release_date\", \"imdb_url\",\n",
    "    \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\",\n",
    "    \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "movies = spark.read.csv(movies_path, sep=\"|\", inferSchema=True).toDF(*movies_columns)\n",
    "\n",
    "movies.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+-----+\n",
      "|userId|count|\n",
      "+------+-----+\n",
      "|   405|  737|\n",
      "|   655|  685|\n",
      "|    13|  636|\n",
      "|   450|  540|\n",
      "|   276|  518|\n",
      "+------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "+-------+-----+\n",
      "|movieId|count|\n",
      "+-------+-----+\n",
      "|     50|  583|\n",
      "|    258|  509|\n",
      "|    100|  508|\n",
      "|    181|  507|\n",
      "|    294|  485|\n",
      "+-------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "Количество записей после фильтрации: 99287\n",
      "+-------+------+------+---------+--------------------+\n",
      "|movieId|userId|rating|timestamp|              weight|\n",
      "+-------+------+------+---------+--------------------+\n",
      "|    242|   196|     3|881250949|5.928798377342577E-6|\n",
      "|    302|   186|     3|891717742| 0.20827499106941064|\n",
      "|    377|    22|     1|878887116|5.576568655535087E-7|\n",
      "|     51|   244|     2|880606923|3.113649646606838E-6|\n",
      "|    346|   166|     1|886397596|0.001018889469706...|\n",
      "+-------+------+------+---------+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "user_activity = ratings.groupBy(\"userId\").count()\n",
    "user_activity.orderBy(\"count\", ascending=False).show(5)\n",
    "\n",
    "movie_popularity = ratings.groupBy(\"movieId\").count()\n",
    "movie_popularity.orderBy(\"count\", ascending=False).show(5)\n",
    "\n",
    "\n",
    "active_users = user_activity.filter(col(\"count\") >= 5).select(\"userId\")\n",
    "filtered_ratings = ratings.join(active_users, on=\"userId\", how=\"inner\")\n",
    "\n",
    "popular_movies = movie_popularity.filter(col(\"count\") >= 5).select(\"movieId\")\n",
    "filtered_ratings = filtered_ratings.join(popular_movies, on=\"movieId\", how=\"inner\")\n",
    "\n",
    "\n",
    "print(f\"Количество записей после фильтрации: {filtered_ratings.count()}\")\n",
    "filtered_ratings.show(5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ratings = filtered_ratings.groupBy(\"userId\").avg(\"rating\").withColumnRenamed(\"avg(rating)\", \"avg_user_rating\")\n",
    "normalized_ratings = filtered_ratings.join(avg_ratings, on=\"userId\")\n",
    "normalized_ratings = normalized_ratings.withColumn(\"normalized_rating\", col(\"rating\") - col(\"avg_user_rating\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 14:00:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.JNIBLAS\n",
      "24/11/27 14:00:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.blas.VectorBLAS\n",
      "24/11/27 14:00:37 WARN InstanceBuilder: Failed to load implementation from:dev.ludovic.netlib.lapack.JNILAPACK\n",
      "24/11/27 14:00:49 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Лучший ранг: 30\n",
      "Лучший параметр регуляризации: 0.1\n",
      "Лучшее число итераций: 15\n",
      "Root-mean-square error: 0.9146304444654756\n"
     ]
    }
   ],
   "source": [
    "# Split data into training and testing sets\n",
    "(train_data, test_data) = normalized_ratings.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Build ALS model\n",
    "als = ALS(\n",
    "    userCol=\"userId\",\n",
    "    itemCol=\"movieId\",\n",
    "    ratingCol=\"rating\",\n",
    "    coldStartStrategy=\"drop\"\n",
    ")\n",
    "\n",
    "# Define parameter grid for hyperparameter tuning\n",
    "paramGrid = ParamGridBuilder() \\\n",
    "    .addGrid(als.rank, [10, 20, 30]) \\\n",
    "    .addGrid(als.maxIter, [10, 15]) \\\n",
    "    .addGrid(als.regParam, [0.01, 0.1, 0.5]) \\\n",
    "    .build()\n",
    "\n",
    "# Define evaluator\n",
    "evaluator = RegressionEvaluator(\n",
    "    metricName=\"rmse\",\n",
    "    labelCol=\"rating\",\n",
    "    predictionCol=\"prediction\"\n",
    ")\n",
    "\n",
    "# Set up cross-validation\n",
    "crossval = CrossValidator(\n",
    "    estimator=als,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3\n",
    ")\n",
    "\n",
    "cv_model = crossval.fit(train_data)\n",
    "best_model = cv_model.bestModel\n",
    "\n",
    "# Print best hyperparameters\n",
    "print(f\"Лучший ранг: {best_model.rank}\")\n",
    "print(f\"Лучший параметр регуляризации: {best_model._java_obj.parent().getRegParam()}\")\n",
    "print(f\"Лучшее число итераций: {best_model._java_obj.parent().getMaxIter()}\")\n",
    "\n",
    "predictions = best_model.transform(test_data)\n",
    "\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "print(f\"Root-mean-square error: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/11/27 14:01:51 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------------------------------------------+------+\n",
      "|features                                                      |rating|\n",
      "+--------------------------------------------------------------+------+\n",
      "|(20,[0,1,2,7,9],[3.3366076946258545,413.0,1.0,1.0,1.0])       |1     |\n",
      "|(20,[0,1,6,7],[4.144967555999756,241.0,1.0,1.0])              |5     |\n",
      "|(20,[0,1,2,3,16,17],[3.726996898651123,151.0,1.0,1.0,1.0,1.0])|4     |\n",
      "|(20,[0,1,2,3,6,15],[4.275229454040527,324.0,1.0,1.0,1.0,1.0]) |5     |\n",
      "|(20,[0,1,4,6],[4.048789978027344,66.0,1.0,1.0])               |4     |\n",
      "+--------------------------------------------------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Combining ALS predictions with movie data\n",
    "predictions_with_content = best_model.transform(normalized_ratings).join(movies, on=\"movieId\", how=\"left\")\n",
    "\n",
    "# Add the popularity of movies\n",
    "movie_popularity = ratings.groupBy(\"movieId\").count().withColumnRenamed(\"count\", \"popularity\")\n",
    "predictions_with_content = predictions_with_content.join(movie_popularity, on=\"movieId\", how=\"left\")\n",
    "\n",
    "# Build final dataset\n",
    "feature_columns = [\n",
    "    \"prediction\", \"popularity\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\",\n",
    "    \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\",\n",
    "    \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"\n",
    "]\n",
    "\n",
    "# Combine all features in vector\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=feature_columns, outputCol=\"features\")\n",
    "final_data = assembler.transform(predictions_with_content)\n",
    "\n",
    "# Checking final structure\n",
    "final_data.select(\"features\", \"rating\").show(5, truncate=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.004210 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 528\n",
      "[LightGBM] [Info] Number of data points in the train set: 79429, number of used features: 20\n",
      "[LightGBM] [Info] Start training from score 3.535988\n",
      "RMSE для гибридной модели: 0.6610522241515715\n"
     ]
    }
   ],
   "source": [
    "final_data_pd = final_data.select(\"features\", \"rating\").toPandas()\n",
    "\n",
    "X = np.vstack(final_data_pd[\"features\"].values)\n",
    "y = final_data_pd[\"rating\"].values\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# LightGBM\n",
    "model = LGBMRegressor()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict and score\n",
    "y_pred = model.predict(X_test)\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(f\"RMSE для гибридной модели: {rmse}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Топ-10 фильмов для пользователя:\n",
      "     movieId  prediction  lightgbm_predicted_rating  final_predicted_rating\n",
      "78       483    4.854363                   4.916336                4.872955\n",
      "81       127    4.725800                   4.930145                4.787103\n",
      "94       357    4.734693                   4.904951                4.785770\n",
      "120      134    4.728677                   4.898746                4.779697\n",
      "29        64    4.711306                   4.914461                4.772252\n",
      "128      513    4.687511                   4.891517                4.748713\n",
      "80       603    4.685423                   4.883041                4.744708\n",
      "117      178    4.663743                   4.858371                4.722132\n",
      "40       498    4.655439                   4.862816                4.717652\n",
      "83        98    4.651610                   4.831943                4.705710\n"
     ]
    }
   ],
   "source": [
    "# Test date for user \n",
    "test_user = 10\n",
    "user_data = final_data.filter(col(\"userId\") == test_user).select(\"features\", \"movieId\")\n",
    "\n",
    "# Predict Hybrid model (LightGBM)\n",
    "user_data_pd = user_data.toPandas()\n",
    "X_user = np.vstack(user_data_pd[\"features\"].values)\n",
    "predicted_ratings = model.predict(X_user)\n",
    "\n",
    "# Add predict LightGBM in DataFrame\n",
    "lightgbm_predictions = pd.DataFrame({\n",
    "    \"movieId\": user_data_pd[\"movieId\"],\n",
    "    \"lightgbm_predicted_rating\": predicted_ratings\n",
    "})\n",
    "\n",
    "# ALS predict for user\n",
    "als_predictions = predictions_with_content.filter(col(\"userId\") == test_user).select(\"movieId\", \"prediction\")\n",
    "\n",
    "# Convert predict ALS in Pandas\n",
    "als_predictions_pd = als_predictions.toPandas()\n",
    "\n",
    "# Merge ALS и LightGBM on movieId\n",
    "final_predictions = pd.merge(\n",
    "    als_predictions_pd,\n",
    "    lightgbm_predictions,\n",
    "    on=\"movieId\"\n",
    ")\n",
    "\n",
    "# Weighing predictions\n",
    "alpha = 0.7\n",
    "final_predictions[\"final_predicted_rating\"] = (\n",
    "    alpha * final_predictions[\"prediction\"] + (1 - alpha) * final_predictions[\"lightgbm_predicted_rating\"]\n",
    ")\n",
    "\n",
    "# Sorting movies according final predicted rating \n",
    "final_recommendations = final_predictions.sort_values(by=\"final_predicted_rating\", ascending=False)\n",
    "\n",
    "# Print Top-10 movies\n",
    "print(\"Топ-10 фильмов для пользователя:\")\n",
    "print(final_recommendations.head(10))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
